{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f526b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "# %matplotlib widget\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "sns.set_palette(['#1E1E1E', '#BB3524', '#F5D54A', '#384827', '#282F44'])\n",
    "sns.set_context('paper')\n",
    "sns.set_style({'axes.axisbelow': True, \n",
    "               'axes.edgecolor': '.15',\n",
    "               'axes.facecolor': 'white',\n",
    "               'axes.grid': False, \n",
    "               'axes.labelcolor': '.15', \n",
    "               'figure.facecolor': 'white', \n",
    "               'grid.color': '.15',\n",
    "               'grid.linestyle': ':', \n",
    "               'grid.alpha': .5, \n",
    "               'image.cmap': 'Greys', \n",
    "               'legend.frameon': False, \n",
    "               'legend.numpoints': 1, \n",
    "               'legend.scatterpoints': 1,\n",
    "               'lines.solid_capstyle': 'butt', \n",
    "               'axes.spines.right': False, \n",
    "               'axes.spines.top': False,  \n",
    "               'text.color': '.15',  \n",
    "               'xtick.top': False, \n",
    "               'ytick.right': False, \n",
    "               'xtick.color': '.15',\n",
    "               'xtick.direction': 'out', \n",
    "               'ytick.color': '.15', \n",
    "               'ytick.direction': 'out', \n",
    "              })\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "FONT_SIZE_PT = 5\n",
    "matplotlib.rcParams['font.family'] = 'Arial'\n",
    "matplotlib.rcParams['font.size'] = FONT_SIZE_PT\n",
    "matplotlib.rcParams['axes.labelsize'] = FONT_SIZE_PT\n",
    "matplotlib.rcParams['axes.titlesize'] = FONT_SIZE_PT\n",
    "matplotlib.rcParams['figure.titlesize'] = FONT_SIZE_PT\n",
    "matplotlib.rcParams['xtick.labelsize'] = FONT_SIZE_PT\n",
    "matplotlib.rcParams['ytick.labelsize'] = FONT_SIZE_PT\n",
    "matplotlib.rcParams['legend.fontsize'] = FONT_SIZE_PT\n",
    "matplotlib.rcParams['legend.title_fontsize'] = FONT_SIZE_PT\n",
    "\n",
    "matplotlib.rcParams['xtick.major.size'] = matplotlib.rcParams['ytick.major.size'] = 2\n",
    "matplotlib.rcParams['xtick.major.width'] = matplotlib.rcParams['ytick.major.width'] = 0.5\n",
    "\n",
    "\n",
    "matplotlib.rcParams['xtick.minor.size'] = matplotlib.rcParams['ytick.minor.size'] = 1\n",
    "\n",
    "matplotlib.rcParams['xtick.minor.width'] = matplotlib.rcParams['ytick.minor.width'] = 0.5\n",
    "\n",
    "matplotlib.rcParams['axes.linewidth'] = 0.5\n",
    "matplotlib.rcParams['lines.linewidth'] = 0.5\n",
    "matplotlib.rcParams['grid.linewidth'] = 0.25\n",
    "matplotlib.rcParams['patch.linewidth'] = 0.25\n",
    "matplotlib.rcParams['lines.markeredgewidth'] = 0.25\n",
    "matplotlib.rcParams['lines.markersize'] = 2\n",
    "\n",
    "FIVE_MM_IN_INCH = 0.19685\n",
    "DPI = 600\n",
    "matplotlib.rcParams['figure.figsize'] = (10 * FIVE_MM_IN_INCH, 9 * FIVE_MM_IN_INCH)\n",
    "matplotlib.rcParams['savefig.dpi'] = DPI\n",
    "matplotlib.rcParams['figure.dpi'] = DPI // 4\n",
    "\n",
    "\n",
    "#http://phyletica.org/matplotlib-fonts/\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64e1d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import palettable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28849b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HAVE_SNAKEMAKE = 'snakemake' in locals()\n",
    "\n",
    "if HAVE_SNAKEMAKE:\n",
    "    input_peaklists = snakemake.input.peaklists\n",
    "    input_stats = snakemake.input.stats\n",
    "    \n",
    "    input_marcs_features = snakemake.input.marcs_features\n",
    "    input_marcs_gene_label_map = snakemake.input.marcs_gene_label_map\n",
    "    \n",
    "    param_op = snakemake.params.agg_op_of_interest\n",
    "    \n",
    "    output_csv = snakemake.output.csv\n",
    "    output_xlsx = snakemake.output.xlsx\n",
    "\n",
    "    param_analysis_mode = snakemake.params['analysis_mode']\n",
    "    param_correlation_method = snakemake.params['correlation_method']\n",
    "    param_cell_line = snakemake.params['cell_line']\n",
    "    param_bin_size = snakemake.params['bin_size']\n",
    "    \n",
    "    param_marcs_gene_label_separator = snakemake.params['marcs_gene_label_separator']\n",
    "    param_output_header_sep = snakemake.params.get('output_header_sep', '__')\n",
    "    \n",
    "else:\n",
    "    print(\"No snakemake -- DEBUG MODE\")\n",
    "    \n",
    "    _OUTDIR = '.nb-testing-outputs'\n",
    "    if not os.path.isdir(_OUTDIR):\n",
    "        os.makedirs(_OUTDIR)\n",
    "   \n",
    "    param_bin_size = 1000\n",
    "    input_peaklists = []\n",
    "    input_stats = []\n",
    "    \n",
    "    param_cell_line = 'K562'\n",
    "    \n",
    "    _bin_size = 1000\n",
    "    _pseudocount = 100\n",
    "    _min_periods = 1\n",
    "    \n",
    "    for _cell_line in [param_cell_line]:\n",
    "        for dataset in ['feature_accessibility', 'feature_histone', 'protein']:\n",
    "            input_peaklists.append(f'../../output/final/encode/encode_{dataset}_data.{_cell_line}.bed.tsv.gz')\n",
    "        \n",
    "        input_stats.append(f'../../output/final/bedstats/genomic-window-matrix-stats-{param_bin_size}bp_params_pc_{_pseudocount}_mp_{_min_periods}_from_bed.{_cell_line}.h5')\n",
    "    \n",
    "    input_marcs_features = '../../output/interim/marcs/table-s3.long.tsv.gz'\n",
    "    input_marcs_gene_label_map = '../../output/interim/marcs/genes_to_marcs_from_table-s1.tsv.gz'\n",
    "\n",
    "    output_xlsx = os.path.join(_OUTDIR, f'bedstats_consolidated_{param_cell_line}.xlsx')\n",
    "    output_csv = os.path.join(_OUTDIR, f'bedstats_consolidated_{param_cell_line}.csv')\n",
    "    \n",
    "    param_op = 'max'\n",
    "    \n",
    "    param_analysis_mode = 'full'\n",
    "    param_correlation_method = 'kendall'\n",
    "    \n",
    "    param_marcs_gene_label_separator = '||'\n",
    "    \n",
    "    param_output_header_sep = '__'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f2bd1b",
   "metadata": {},
   "source": [
    "The goal of this notebook is to consolidate the various ChIP-seq statistics into something that can be readily used to make summary plots.\n",
    "\n",
    "\n",
    "# Input\n",
    "\n",
    "Load the required data from HDF5 stores.\n",
    "\n",
    "## Peaklist\n",
    "\n",
    "First, the peaklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f9cbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CELL_LINE_COLUMN = 'Biosample term name'\n",
    "_peaklists = [\n",
    "    pd.read_csv(peaklist_file, sep='\\t', index_col=0) for peaklist_file in input_peaklists\n",
    "]\n",
    "\n",
    "peaklist = pd.concat(_peaklists)\n",
    "peaklist['Factor_Cell_Identifier'] = peaklist['Factor'].str.cat(peaklist[CELL_LINE_COLUMN], sep='-').str.cat(peaklist.index, sep='-')\n",
    "\n",
    "peaklist['is_protein'] = peaklist['FactorType'] == 'protein'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b6c133",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaklist['FactorType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5368d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaklist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1561e00",
   "metadata": {},
   "source": [
    "## Stats\n",
    "\n",
    "Load the most important information that we will need to make the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b9e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_load = {\n",
    "    # Correlation between ChIP-seq signals\n",
    "    f'{param_correlation_method}_correlation': f'correlation_matrix/{param_correlation_method}',\n",
    "    \n",
    "    # Mutual information \n",
    "    'mi': f'mutual_information',\n",
    "    \n",
    "    # Marginal entropy\n",
    "    'entropy': f'entropy/marginal',\n",
    "    \n",
    "    # Uncertainty coefficient (by rows)\n",
    "    'normalised_mi': 'uncertainty_coefficient/by_rows',\n",
    "    \n",
    "    # Joint counts (all four possible combinations)\n",
    "    'counts_true_true': 'counts/joint/a:True_b:True',\n",
    "    'counts_true_false': 'counts/joint/a:True_b:False',\n",
    "    'counts_false_true': 'counts/joint/a:False_b:True',\n",
    "    'counts_false_false': 'counts/joint/a:False_b:False',\n",
    "    \n",
    "}\n",
    "\n",
    "data = {k : [] for k in data_to_load}\n",
    "\n",
    "seen_indices = set()\n",
    "\n",
    "for filename in input_stats:\n",
    "    with pd.HDFStore(filename, 'r') as store:\n",
    "        for name, key in data_to_load.items():\n",
    "            df = store[f'/{param_analysis_mode}/{key}']\n",
    "            \n",
    "            seen_indices.update(df.index)\n",
    "            data[name].append(df)\n",
    "\n",
    "data = {\n",
    "    k: pd.concat(v) for k,v in data.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d19d88",
   "metadata": {},
   "source": [
    "Reindex the peaklist with identifiers in data to make our life easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4375596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaklist_correlation_indexed = []\n",
    "\n",
    "for ix in seen_indices:\n",
    "    if not ix.startswith('dataset'):\n",
    "        continue\n",
    "        \n",
    "    # Basically just decompose the three values separated by \":\" to get the index in peaklist\n",
    "    __, peaklist_ix, agg_op = ix.split(':')\n",
    "    \n",
    "    if peaklist_ix in peaklist.index:\n",
    "        peaklist_correlation_indexed.append([ix, peaklist_ix, agg_op])\n",
    "\n",
    "peaklist_correlation_indexed = pd.DataFrame(peaklist_correlation_indexed, columns=['correlation_index', 'peaklist_index', 'agg_op'])\n",
    "peaklist_correlation_indexed = peaklist_correlation_indexed.join(peaklist, on='peaklist_index').set_index('correlation_index')\n",
    "\n",
    "peaklist_correlation_indexed['Factor_Cell_Identifier_op'] = peaklist_correlation_indexed['Factor_Cell_Identifier'].str.cat(peaklist_correlation_indexed['agg_op'], sep=':')\n",
    "peaklist_correlation_indexed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4a768d",
   "metadata": {},
   "source": [
    "And now reindex everything using `Factor_Cell_Identifier` to make it even easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60326a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not peaklist_correlation_indexed['Factor_Cell_Identifier'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadb8494",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, df in data.items():\n",
    "        \n",
    "    new_index = []\n",
    "    for ix in df.index:\n",
    "        \n",
    "        try:\n",
    "            new_index.append(peaklist_correlation_indexed.loc[ix, 'Factor_Cell_Identifier'])\n",
    "        except KeyError:\n",
    "            new_index.append(ix)\n",
    "    \n",
    "    data[k].index = new_index\n",
    "    \n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        \n",
    "        new_columns = []\n",
    "        for ix in df.columns:\n",
    "            try:\n",
    "                new_columns.append(peaklist_correlation_indexed.loc[ix, 'Factor_Cell_Identifier'])\n",
    "            except KeyError:\n",
    "                new_columns.append(ix)\n",
    "                \n",
    "        data[k].columns = new_columns\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa04bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaklist_correlation_indexed = peaklist_correlation_indexed.set_index('Factor_Cell_Identifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b3045e",
   "metadata": {},
   "source": [
    "## MARCS Features\n",
    "\n",
    "Figure out which MARCS gene labels we will need to map ChIP-seq to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76794b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "peaklist_to_marcs_map = peaklist_correlation_indexed['marcs_gene_label'].dropna().str.split(re.escape(param_marcs_gene_label_separator), expand=True).stack().reset_index()\n",
    "peaklist_to_marcs_map.columns = ['correlation_index', 'no', 'marcs_gene_label']\n",
    "peaklist_to_marcs_map = peaklist_to_marcs_map.drop(columns='no')\n",
    "peaklist_to_marcs_map = peaklist_to_marcs_map.drop_duplicates()\n",
    "peaklist_to_marcs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07d041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaklist_to_marcs_map.groupby('correlation_index')['marcs_gene_label'].nunique().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c17b8c3",
   "metadata": {},
   "source": [
    "Now let's reindex the MARCS feature dataframe by `correlation_index` column, not `Gene label`.\n",
    "In case where one Factor maps to multiple estimates of feature effect, use the row with the lowest P-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3028090",
   "metadata": {},
   "outputs": [],
   "source": [
    "marcs_features_long = pd.read_csv(input_marcs_features, sep='\\t').set_index(['Gene label', 'Feature'])\n",
    "marcs_features_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ac570-5ca5-46eb-8855-2acab4661d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86ebb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "marcs_feature_list = helpers.MARCS_FEATURE_ORDER\n",
    "assert set(marcs_feature_list) == set(marcs_features_long.reset_index()['Feature'].unique())\n",
    "\n",
    "_index_df = peaklist_to_marcs_map\n",
    "_column_to_reindex_to = 'correlation_index'\n",
    "\n",
    "marcs_features_reindexed = {}\n",
    "\n",
    "for feature in marcs_feature_list:\n",
    "    feature_df = marcs_features_long.xs(feature, level='Feature')\n",
    "    \n",
    "    _df = []\n",
    "    \n",
    "    # Solve multimappings where one gene name maps to multiple MARCS gene names,\n",
    "    # by taking the entry with lowest p-value\n",
    "    for __, _subdata in _index_df.join(feature_df, on='marcs_gene_label').dropna(subset=['P value']).groupby(_column_to_reindex_to):\n",
    "        _subdata = _subdata.loc[_subdata['P value'].idxmin()]\n",
    "        _df.append(_subdata)\n",
    "        \n",
    "    _df = pd.DataFrame(_df).set_index(_column_to_reindex_to)\n",
    "    assert not _df.index.duplicated().any()\n",
    "    \n",
    "    marcs_features_reindexed[feature] = _df\n",
    "    \n",
    "marcs_features_reindexed_wide = pd.concat(marcs_features_reindexed.values(), keys=marcs_features_reindexed.keys(), axis=1)\n",
    "marcs_features_reindexed_wide = marcs_features_reindexed_wide.swaplevel(axis=1)\n",
    "marcs_features_reindexed_wide.sort_index(axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d821f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "marcs_features_reindexed_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c9e4fa",
   "metadata": {},
   "source": [
    "# Output\n",
    "\n",
    "## Prep\n",
    "At this point we have most of the data ready, let's combine it to the format that we can save as CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b2f2c7",
   "metadata": {},
   "source": [
    "We want protein (and other) ChIP-seqs as rows, and non-protein ChIP-seqs as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75647c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_indices = peaklist_correlation_indexed[peaklist_correlation_indexed['is_protein']].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9c2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_adjusted = {}\n",
    "for k, v in data.items():\n",
    "    # Entropy has to be dealt a bit differently as it is a series\n",
    "    if k == 'entropy':\n",
    "        \n",
    "        # Get entropy of rows first\n",
    "        df = v.copy()\n",
    "        df = pd.DataFrame(df)\n",
    "        df.columns = pd.MultiIndex.from_tuples(\n",
    "            [('entropy_by_row', 'entropy_by_row')],\n",
    "            names=['header', 'column']\n",
    "        )\n",
    "        data_adjusted['entropy_by_row'] = df \n",
    "        \n",
    "        # Now get the entropy of columns. We only need to do that for non-protein indices\n",
    "        non_protein_indices = v.index.difference(protein_indices)\n",
    "        df = v.copy()\n",
    "        df = df.loc[non_protein_indices]\n",
    "        \n",
    "        df = pd.DataFrame(\n",
    "            np.broadcast_to(df, (len(v), len(non_protein_indices))), \n",
    "            index=v.index, columns=non_protein_indices\n",
    "        )\n",
    "        \n",
    "        df.columns = pd.MultiIndex.from_tuples(\n",
    "            zip(np.repeat('entropy_by_col', len(df.columns)), df.columns),\n",
    "            names=['header', 'column']\n",
    "        )\n",
    "        \n",
    "        df = df.sort_index(axis=1)\n",
    "        data_adjusted['entropy_by_col'] = df \n",
    "    else:\n",
    "        # For everything else we need to make it asymmetric,\n",
    "        # Take only non-proteins as columns\n",
    "        non_protein_indices = v.columns.difference(protein_indices)\n",
    "        df = v.loc[:, non_protein_indices].copy()\n",
    "        df.columns = pd.MultiIndex.from_tuples(\n",
    "            zip(np.repeat(k, len(df.columns)), df.columns),\n",
    "            names=['header', 'column']\n",
    "        )\n",
    "        \n",
    "        df = df.sort_index(axis=1)\n",
    "        \n",
    "        data_adjusted[k] = df\n",
    "        \n",
    "        \n",
    "# also add marcs_data as well\n",
    "data_adjusted['marcs_feature_effect'] = marcs_features_reindexed_wide['Effect'].copy()\n",
    "# Use strong significance category\n",
    "data_adjusted['marcs_feature_significant_category'] = marcs_features_reindexed_wide['significant_category_strong'].copy()\n",
    "\n",
    "for marcs_key in ['marcs_feature_effect', 'marcs_feature_significant_category']:\n",
    "    data_adjusted[marcs_key].columns = pd.MultiIndex.from_tuples(\n",
    "            zip(np.repeat(marcs_key, len(data_adjusted[marcs_key].columns)), data_adjusted[marcs_key].columns),\n",
    "            names=['header', 'column']\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712a83ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_protein_peaklist = peaklist_correlation_indexed.loc[\n",
    "    :,\n",
    "    ['File accession', CELL_LINE_COLUMN, 'Factor', 'FactorType', 'marcs_gene_label']\n",
    "].copy()\n",
    "\n",
    "data_protein_peaklist.columns = pd.MultiIndex.from_tuples(\n",
    "    [['metadata', 'encode_id'], ['metadata', 'cell_line'], ['metadata', 'factor'], ['metadata', 'factor_type'], ['metadata', 'marcs_gene_label']],\n",
    "    name=['header', 'column']\n",
    ")\n",
    "data_protein_peaklist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066a019c",
   "metadata": {},
   "source": [
    "Assemble data for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8fc9e3-e3e5-4b6b-9463-e50bd4be3c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_adjusted['normalised_mi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344a45e6-e4f8-4d23-9ce8-cdf29c48fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_adjusted[f'{param_correlation_method}_correlation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1289f3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_output = data_protein_peaklist.copy()\n",
    "data_for_output = data_for_output \\\n",
    "    .join(data_adjusted['marcs_feature_significant_category']) \\\n",
    "    .join(data_adjusted['normalised_mi']) \\\n",
    "    .join(data_adjusted['entropy_by_row']) \\\n",
    "    .join(data_adjusted[f'{param_correlation_method}_correlation']) \\\n",
    "    .join(data_adjusted['mi']) \\\n",
    "    .join(data_adjusted['entropy_by_col']) \\\n",
    "    .join(data_adjusted['counts_true_true']) \\\n",
    "    .join(data_adjusted['counts_false_true']) \\\n",
    "    .join(data_adjusted['counts_true_false']) \\\n",
    "    .join(data_adjusted['counts_false_false']) \\\n",
    "    .sort_index()\n",
    "data_for_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30076d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_output_squashed_header = data_for_output.copy()\n",
    "data_for_output_squashed_header.columns = [param_output_header_sep.join(c) for c in data_for_output_squashed_header.columns]\n",
    "\n",
    "data_for_output_squashed_header.to_csv(output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabbe9b4-61c8-4800-9f79-809342d6d690",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_output_squashed_header.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64300d35-77b7-41e0-9d4b-1abbddbe20d0",
   "metadata": {},
   "source": [
    "# Excel output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ec13a-7bc4-45f6-a8c4-432dbe746450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "from seaborn.utils import relative_luminance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309c14f1-dcce-4b0c-8623-cbe0113afd49",
   "metadata": {},
   "source": [
    "### Summary sheet (main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e557c75c-eff4-4a4a-b93c-0b4680473252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel = data_for_output_squashed_header.copy()\n",
    "\n",
    "# Shorten MARCS categories so they don't take so much space in excel\n",
    "df_excel.replace(\n",
    "    {c:  {'Neither': 'N', 'Strongly recruited': 'R', 'Strongly excluded': 'E'} for c in df_excel if c.partition(param_output_header_sep)[0] == 'marcs_feature_significant_category'},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "RENAMES = {}\n",
    "COLUMN_GROUPS = {\n",
    "    'Metadata': \n",
    "        ([c for c in df_excel if c.partition(param_output_header_sep)[0] == 'metadata']),\n",
    "    'Normalised MI': \n",
    "         ([c for c in df_excel if c.partition(param_output_header_sep)[0] == 'normalised_mi']),\n",
    "    '{} correlation'.format(param_correlation_method.capitalize()): \n",
    "          ([c for c in df_excel if c.partition(param_output_header_sep)[0] == f'{param_correlation_method}_correlation']),\n",
    "    'MARCS Feature Response (R: strongly recruited, E: strongly excluded, N: neither)':\n",
    "        ([c for c in df_excel if c.partition(param_output_header_sep)[0] == 'marcs_feature_significant_category']),\n",
    "    'MI': \n",
    "        ([c for c in df_excel if c.partition(param_output_header_sep)[0] == 'mi']),\n",
    "    'Entropy (row)':\n",
    "        ([c for c in df_excel if c.partition(param_output_header_sep)[0] == 'entropy_by_row']),\n",
    "    'Entropy (col)':\n",
    "        ([c for c in df_excel if c.partition(param_output_header_sep)[0] == 'entropy_by_col']),\n",
    "    f'Number of {param_bin_size}bp bins where row and col peaks co-occur': \n",
    "        ([c for c in df_excel if c.partition(param_output_header_sep)[0] == 'counts_true_true']),\n",
    "    f'Number of {param_bin_size}bp bins where row peaks occur without col peaks': \n",
    "        ([c for c in df_excel if c.partition(param_output_header_sep)[0] == 'counts_true_false']),\n",
    "    f'Number of {param_bin_size}bp bins where col peaks occur without row peaks': \n",
    "        ([c for c in df_excel if c.partition(param_output_header_sep)[0] == 'counts_false_true']),\n",
    "    f'Number of {param_bin_size}bp bins where neither row, nor col peaks are present': \n",
    "        ([c for c in df_excel if c.partition(param_output_header_sep)[0] == 'counts_false_false']),\n",
    "    \n",
    "}\n",
    "\n",
    "RENAMES = {c: c.partition(param_output_header_sep)[2] for c in df_excel.columns}\n",
    "\n",
    "writer = pd.ExcelWriter(output_xlsx, engine='xlsxwriter')\n",
    "workbook = writer.book\n",
    "\n",
    "bold = workbook.add_format({'bold': True})\n",
    "bold_right = workbook.add_format({'bold': True, 'right': 1})\n",
    "\n",
    "bold_rotated = workbook.add_format({'bold': True, 'rotation':90})\n",
    "bold_rotated_right = workbook.add_format({'bold': True, 'rotation':90, 'right': 1})\n",
    "\n",
    "merged_format = workbook.add_format({\n",
    "    'bold': 1,\n",
    "    'align': 'center',\n",
    "    'valign': 'vcenter',\n",
    "    'right': 1,\n",
    "})\n",
    "\n",
    "right_border = workbook.add_format({\n",
    "    'right': 1,\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "sheet_name = f\"summary_{param_cell_line}\"\n",
    "\n",
    "first_data_row = 2\n",
    "first_data_col = 0\n",
    "df_excel.to_excel(\n",
    "    writer, \n",
    "    sheet_name=sheet_name, \n",
    "    startrow=first_data_row, \n",
    "    startcol=first_data_col, \n",
    "    index=False, \n",
    "    header=False\n",
    ")\n",
    "\n",
    "last_data_row = first_data_row + len(df_excel)\n",
    "last_data_col = first_data_col + len(df_excel.columns)\n",
    "\n",
    "worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "\n",
    "SEPARATOR_COLUMNS = {v[-1] for v in COLUMN_GROUPS.values()}\n",
    "\n",
    "colname_to_index_map = {}\n",
    "for i, col in enumerate(df_excel.columns, start=first_data_col):\n",
    "    fmt_ = bold_rotated if not col in SEPARATOR_COLUMNS else bold_rotated_right\n",
    "    \n",
    "    worksheet.write(first_data_row-1, i, RENAMES.get(col, col), fmt_)\n",
    "    colname_to_index_map[col] = i\n",
    "\n",
    "\n",
    "for merged_name, col_list in COLUMN_GROUPS.items():\n",
    "    _first = colname_to_index_map[col_list[0]]\n",
    "    _last = colname_to_index_map[col_list[-1]]\n",
    "    \n",
    "    if _first == _last:\n",
    "        # Cannot merge one column only\n",
    "        worksheet.write(first_data_row-2, _first, merged_name, merged_format)\n",
    "    else:\n",
    "        worksheet.merge_range(\n",
    "            first_data_row-2, colname_to_index_map[col_list[0]], \n",
    "            first_data_row-2, colname_to_index_map[col_list[-1]],\n",
    "            merged_name,\n",
    "            merged_format\n",
    "        )\n",
    "\n",
    "for col in SEPARATOR_COLUMNS:\n",
    "    worksheet.set_column(colname_to_index_map[col], colname_to_index_map[col], cell_format=right_border)\n",
    "    \n",
    "for cols, width in [\n",
    "    (COLUMN_GROUPS[cg], 4) for cg in ['Normalised MI', '{} correlation'.format(param_correlation_method.capitalize()), 'MARCS Feature Response (R: strongly recruited, E: strongly excluded, N: neither)']\n",
    "]:\n",
    "    for col in cols:\n",
    "        worksheet.set_column(colname_to_index_map[col], colname_to_index_map[col], width)\n",
    "        \n",
    "    \n",
    "color_red = '#d6604d'\n",
    "color_white = '#f7f7f7'\n",
    "color_blue = '#4393c3'\n",
    "\n",
    "        \n",
    "for (val, color) in [('R', color_red), ('E', color_blue)]:\n",
    "    for col in COLUMN_GROUPS['MARCS Feature Response (R: strongly recruited, E: strongly excluded, N: neither)']:\n",
    "        fmt_ = workbook.add_format({\n",
    "            'bg_color': color,\n",
    "            'font_color': \"#000000\" if relative_luminance(color) > .408 else \"#FFFFFF\"\n",
    "        })\n",
    "\n",
    "        worksheet.conditional_format(\n",
    "            first_data_row, colname_to_index_map[col], \n",
    "            last_data_row, colname_to_index_map[col],\n",
    "            {\n",
    "                'type': 'cell',\n",
    "                'criteria': 'equal to',\n",
    "                'value': f'\"{val}\"',\n",
    "                'format': fmt_,\n",
    "            }\n",
    "        )\n",
    "    \n",
    "\n",
    "for col in COLUMN_GROUPS['Normalised MI']:\n",
    "    worksheet.conditional_format(\n",
    "        first_data_row, colname_to_index_map[col], \n",
    "        last_data_row, colname_to_index_map[col],\n",
    "        {\n",
    "            'type': '2_color_scale',\n",
    "            'min_type': 'num',\n",
    "            'max_type': 'num',\n",
    "            'min_value': 0,\n",
    "            'max_value': 0.5,\n",
    "            'max_color': '#084081',\n",
    "            'min_color': '#f7fcf0',\n",
    "\n",
    "        }\n",
    "    )\n",
    "    \n",
    "for col in COLUMN_GROUPS['{} correlation'.format(param_correlation_method.capitalize())]:\n",
    "    worksheet.conditional_format(\n",
    "        first_data_row, colname_to_index_map[col], \n",
    "        last_data_row, colname_to_index_map[col],\n",
    "        {\n",
    "            'type': '3_color_scale',\n",
    "            'min_type': 'num',\n",
    "            'max_type': 'num',\n",
    "            'mid_type': 'num',\n",
    "            'min_value': -0.5,\n",
    "            'max_value': 0.5,\n",
    "            'mid_value': 0,\n",
    "            'max_color': color_red,\n",
    "            'mid_color': color_white,\n",
    "            'min_color': color_blue,\n",
    "\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "data_bar_cols = []\n",
    "for col_grp in [\n",
    "    'Entropy (row)', \n",
    "    'MI', \n",
    "    f'Number of {param_bin_size}bp bins where row and col peaks co-occur',\n",
    "    f'Number of {param_bin_size}bp bins where row peaks occur without col peaks', \n",
    "    f'Number of {param_bin_size}bp bins where col peaks occur without row peaks', \n",
    "    f'Number of {param_bin_size}bp bins where neither row, nor col peaks are present',\n",
    "]:\n",
    "    data_bar_cols.extend(COLUMN_GROUPS[col_grp])\n",
    "\n",
    "for col in data_bar_cols:\n",
    "    worksheet.conditional_format(\n",
    "        first_data_row, colname_to_index_map[col], \n",
    "        last_data_row, colname_to_index_map[col],\n",
    "        {\n",
    "            'type': 'data_bar',\n",
    "            'min_type': 'percentile',\n",
    "            'max_type': 'percentile',\n",
    "            'min_value': 1,\n",
    "            'max_value': 99,\n",
    "\n",
    "        }\n",
    "    )\n",
    "    \n",
    "worksheet.freeze_panes(first_data_row, colname_to_index_map[COLUMN_GROUPS['Normalised MI'][0]])\n",
    "worksheet.autofilter(first_data_row-1, first_data_col, last_data_row, last_data_col)\n",
    "        \n",
    "writer.save()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efb3c92-bd41-4ebb-a393-2f3b17a1294c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7e3c78-6462-4c9e-b09f-7b3adb014d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e17b4a3-9e4e-4e64-9dbd-9b54588ba47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069898d9-c540-47e7-b316-d37fd61fb6be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
