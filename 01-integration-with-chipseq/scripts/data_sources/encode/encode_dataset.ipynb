{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7882fe-efdf-4beb-b445-87f027f9118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "sns.set_palette(['#1E1E1E', '#BB3524', '#F5D54A', '#384827', '#282F44'])\n",
    "sns.set_context('paper')\n",
    "sns.set_style({'axes.axisbelow': True, \n",
    "               'axes.edgecolor': '.15',\n",
    "               'axes.facecolor': 'white',\n",
    "               'axes.grid': False, \n",
    "               'axes.labelcolor': '.15', \n",
    "               'figure.facecolor': 'white', \n",
    "               'grid.color': '.15',\n",
    "               'grid.linestyle': ':', \n",
    "               'grid.alpha': .5, \n",
    "               'image.cmap': 'Greys', \n",
    "               'legend.frameon': False, \n",
    "               'legend.numpoints': 1, \n",
    "               'legend.scatterpoints': 1,\n",
    "               'lines.solid_capstyle': 'butt', \n",
    "               'axes.spines.right': False, \n",
    "               'axes.spines.top': False,  \n",
    "               'text.color': '.15',  \n",
    "               'xtick.top': False, \n",
    "               'ytick.right': False, \n",
    "               'xtick.color': '.15',\n",
    "               'xtick.direction': 'out', \n",
    "               'ytick.color': '.15', \n",
    "               'ytick.direction': 'out', \n",
    "              })\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "FONT_SIZE_PT = 5\n",
    "matplotlib.rcParams['font.family'] = 'Arial'\n",
    "matplotlib.rcParams['font.size'] = FONT_SIZE_PT\n",
    "matplotlib.rcParams['axes.labelsize'] = FONT_SIZE_PT\n",
    "matplotlib.rcParams['axes.titlesize'] = FONT_SIZE_PT\n",
    "matplotlib.rcParams['figure.titlesize'] = FONT_SIZE_PT\n",
    "matplotlib.rcParams['xtick.labelsize'] = FONT_SIZE_PT\n",
    "matplotlib.rcParams['ytick.labelsize'] = FONT_SIZE_PT\n",
    "matplotlib.rcParams['legend.fontsize'] = FONT_SIZE_PT\n",
    "matplotlib.rcParams['legend.title_fontsize'] = FONT_SIZE_PT\n",
    "\n",
    "matplotlib.rcParams['xtick.major.size'] = matplotlib.rcParams['ytick.major.size'] = 2\n",
    "matplotlib.rcParams['xtick.major.width'] = matplotlib.rcParams['ytick.major.width'] = 0.5\n",
    "\n",
    "\n",
    "matplotlib.rcParams['xtick.minor.size'] = matplotlib.rcParams['ytick.minor.size'] = 1\n",
    "\n",
    "matplotlib.rcParams['xtick.minor.width'] = matplotlib.rcParams['ytick.minor.width'] = 0.5\n",
    "\n",
    "matplotlib.rcParams['axes.linewidth'] = 0.5\n",
    "matplotlib.rcParams['lines.linewidth'] = 0.5\n",
    "matplotlib.rcParams['grid.linewidth'] = 0.25\n",
    "matplotlib.rcParams['patch.linewidth'] = 0.25\n",
    "matplotlib.rcParams['lines.markeredgewidth'] = 0.25\n",
    "matplotlib.rcParams['lines.markersize'] = 2\n",
    "\n",
    "FIVE_MM_IN_INCH = 0.19685\n",
    "DPI = 600\n",
    "matplotlib.rcParams['figure.figsize'] = (10 * FIVE_MM_IN_INCH, 9 * FIVE_MM_IN_INCH)\n",
    "matplotlib.rcParams['savefig.dpi'] = DPI\n",
    "matplotlib.rcParams['figure.dpi'] = DPI // 2\n",
    "\n",
    "\n",
    "#http://phyletica.org/matplotlib-fonts/\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57049976-7819-4c22-92aa-fb823ce78fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "HAVE_SNAKEMAKE = 'snakemake' in locals()\n",
    "\n",
    "if HAVE_SNAKEMAKE:\n",
    "    input_marcs_gene_label_map = snakemake.input.marcs_gene_label_map \n",
    "    input_encode_metadata = snakemake.input.encode_metadata \n",
    "   \n",
    "    param_encode_download_dir = str(snakemake.params.encode_download_dir)\n",
    "    \n",
    "    output_tsvs = {\n",
    "        'protein': snakemake.output.protein,\n",
    "        'feature_histone': snakemake.output.feature_histone,\n",
    "        'feature_accessibility': snakemake.output.feature_accessibility,\n",
    "    }\n",
    "    \n",
    "    param_encode_data_type = snakemake.params.encode_data_type\n",
    "    param_cell_line = snakemake.params.cell_line\n",
    "    \n",
    "    param_gene_label_separator = snakemake.params.gene_label_separator\n",
    "    \n",
    "else:\n",
    "    print(\"No snakemake -- DEBUG MODE\")\n",
    "    \n",
    "    _OUTDIR = '.nb-testing-outputs'\n",
    "    if not os.path.isdir(_OUTDIR):\n",
    "        os.makedirs(_OUTDIR)\n",
    "    \n",
    "    input_marcs_gene_label_map = '../../../output/interim/marcs/genes_to_marcs_from_table-s1.tsv.gz'\n",
    "    input_encode_metadata = '../../../data/raw/encode/encode_metadata.2021-11-05.tsv.gz'\n",
    "    \n",
    "    param_encode_data_type = 'bigWig'\n",
    "    param_encode_download_dir = '../../../output/interim/encode/downloaded_datasets'\n",
    "    \n",
    "    output_tsvs = {}\n",
    "    \n",
    "    for k in ['protein', 'feature_histone', 'feature_accessibility']:\n",
    "        output_tsvs[k] = os.path.join(_OUTDIR, f'output.encode_{k}.tsv.gz')\n",
    "\n",
    "    param_cell_line = 'HepG2'\n",
    "    \n",
    "    param_gene_label_separator = '||'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e042044-b66c-4fc2-957f-8158425537ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable_ in [\n",
    "    'input_marcs_gene_label_map',\n",
    "    'input_encode_metadata',\n",
    "    'param_encode_download_dir',\n",
    "    'output_tsvs',\n",
    "    'param_cell_line'\n",
    "]:\n",
    "    value_ = locals()[variable_]\n",
    "    \n",
    "    if isinstance(value_, dict):\n",
    "        iter_ = [(f'{variable_}[{k}]', v) for k,v in value_.items()]\n",
    "    elif isinstance(value_, list):\n",
    "        iter_ = [(variable_, v) for v in value_]\n",
    "    else:\n",
    "        iter_ = [(variable_, value_)]\n",
    "    \n",
    "    for var_, val_ in iter_:\n",
    "        print(f'- {var_} = {val_!r}')\n",
    "\n",
    "        if variable_.startswith('input'):\n",
    "            exists = os.path.isfile(val_)\n",
    "            print(f'  {var_} exists = {exists}')\n",
    "            if not exists:\n",
    "                raise Exception(f\"File described by {var_} does not exist\")\n",
    "        elif var_.startswith('output'):\n",
    "\n",
    "            writable = os.access(os.path.dirname(val_), os.W_OK)\n",
    "            print(f'  {var_} writable = {writable}')\n",
    "            if not writable:\n",
    "                raise Exception(f\"Directory for {var_} is not writable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9753aa1c-0c4a-4697-bf3e-60d5c52589e7",
   "metadata": {},
   "source": [
    "# Load Encode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72581011-a868-4a6a-8cab-179eb4a25dc8",
   "metadata": {},
   "source": [
    "We first load the encode metadata dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d3eb65-4361-4aac-88c7-e373b82b2bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode = pd.read_csv(input_encode_metadata, sep='\\t')\n",
    "data_encode.index = data_encode['File accession']\n",
    "data_encode.index.name = 'Identifier'\n",
    "\n",
    "data_encode['Source'] = 'encode'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3419d685-ea98-42ed-b5ab-cdb999f6e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode['Assay'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dabc14c-94e2-417e-a9fd-fbbe440ee99e",
   "metadata": {},
   "source": [
    "Filter out data that is not useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f767179-854a-4f2d-a34f-7046d9829f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = data_encode['File Status'] == 'released'\n",
    "keep &= data_encode['File analysis status'] == 'released'\n",
    "keep &= data_encode['File assembly'] == 'GRCh38'\n",
    "\n",
    "keep &= data_encode['Assay'].isin(['TF ChIP-seq', 'Histone ChIP-seq', 'DNase-seq', 'ATAC-seq'])\n",
    "\n",
    "\n",
    "if param_encode_data_type == 'bigWig':\n",
    "    keep &= data_encode['File type'] == 'bigWig'\n",
    "elif param_encode_data_type == 'bed':\n",
    "    keep &= data_encode['File type'] == 'bed'\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported data type: {param_encode_data_type=}\")\n",
    "\n",
    "data_encode = data_encode[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f37f95-1541-4690-baff-de0986279102",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode['File type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd595b6-2906-4710-8af1-6b8b2d5d1fc4",
   "metadata": {},
   "source": [
    "This does a good job in subsetting data but we are still left a few cases where we still have multiple, competing output files. Let's identify such cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff0d76a-b2e7-4079-af4a-a0aedbf1b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPECTED_NUMBER_OF_FILES = {\n",
    "    'TF ChIP-seq': 1,\n",
    "    'Histone ChIP-seq': 1,\n",
    "    'DNase-seq': 1,\n",
    "    'ATAC-seq': 1,\n",
    "}\n",
    "\n",
    "EXPECTED_NUMBER_OF_FILES = pd.Series(EXPECTED_NUMBER_OF_FILES, name='expected_number_of_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d234d567-324a-40b5-8c9e-5de802789c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_files_per_experiment = data_encode.groupby('Experiment accession').size()\n",
    "_files_per_experiment.name = 'number_of_files'\n",
    "_assay_lookup = data_encode[['Experiment accession', 'Assay']].drop_duplicates().set_index('Experiment accession')\n",
    "assert not _assay_lookup.index.duplicated().any()\n",
    "_files_per_experiment = pd.DataFrame(_files_per_experiment).join(_assay_lookup).join(EXPECTED_NUMBER_OF_FILES, on='Assay')\n",
    "_files_per_experiment['wrong_number_of_files'] = _files_per_experiment['expected_number_of_files'] != _files_per_experiment['number_of_files']\n",
    "_files_per_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337e5928-68e1-4608-843e-4fd378d6242c",
   "metadata": {},
   "source": [
    "The `True` number below should be very low. If it is not, it likely means that you forgot `&files.preferred_default=true` in your metadata query..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eebd19-81c0-452b-bc8d-ba12b47bff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "_files_per_experiment['wrong_number_of_files'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e38378-894b-4133-bd12-e3c9f3d3ac9d",
   "metadata": {},
   "source": [
    "Chances are that the few duplicates we have there, are there due to different version of analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bae7c3-7634-4301-99ca-93a7d0e36329",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode[data_encode['Experiment accession'].isin(_files_per_experiment[_files_per_experiment['wrong_number_of_files']].index)].sort_values(by=['Experiment accession', 'File analysis title']).head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478953e4-4de6-4aec-a1b9-7d31f243d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analysis_version_priority_order = [\n",
    " 'ENCODE4 v3.0.0 GRCh38',\n",
    " 'ENCODE4 v3.0.0-alpha.2 GRCh38',\n",
    " 'ENCODE4 v1.10.0 GRCh38',\n",
    " 'ENCODE4 v1.9.2 GRCh38',\n",
    " 'ENCODE4 v1.9.1 GRCh38',\n",
    " 'ENCODE4 v1.9.0 GRCh38',\n",
    " 'ENCODE4 v1.8.1 GRCh38',\n",
    " 'ENCODE4 v1.8.0 GRCh38',\n",
    " 'ENCODE4 v1.7.1 GRCh38',\n",
    " 'ENCODE4 v1.7.0 GRCh38',\n",
    " 'ENCODE4 v1.6.1 GRCh38',\n",
    " 'ENCODE4 v1.6.0 GRCh38',\n",
    " 'ENCODE4 v1.5.1 GRCh38',\n",
    " 'ENCODE4 v1.5.0 GRCh38',\n",
    " 'ENCODE4 v1.4.0 GRCh38',\n",
    " 'ENCODE4 v1.1.6 GRCh38',\n",
    " 'ENCODE4 v1.1.5 GRCh38',\n",
    " 'ENCODE4 GRCh38',\n",
    " 'ENCODE3 GRCh38'\n",
    "]\n",
    "\n",
    "assert all(v in data_analysis_version_priority_order for v in data_encode['File analysis title'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c4eb6-4726-41e1-8de8-052b0b4e421a",
   "metadata": {},
   "source": [
    "So keep only the latest version for each experiment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacbc911-5de4-4ba7-aab3-7402ab47c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_clean_encode = []\n",
    "\n",
    "for experiment, subdata in data_encode.groupby('Experiment accession'):\n",
    "    \n",
    "    version_priority = subdata['File analysis title'].apply(data_analysis_version_priority_order.index)\n",
    "    best_version = version_priority.min()\n",
    "    \n",
    "    _clean_encode.append(subdata[version_priority == best_version])\n",
    "    \n",
    "_clean_encode = pd.concat(_clean_encode)\n",
    "\n",
    "data_encode = _clean_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e382a6-7340-43b9-9120-c64df2dfc8dc",
   "metadata": {},
   "source": [
    "This should eliminate most duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f72ae5-fcd2-4799-8042-b76302a8d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "_files_per_experiment = data_encode.groupby('Experiment accession').size()\n",
    "_files_per_experiment.name = 'number_of_files'\n",
    "_assay_lookup = data_encode[['Experiment accession', 'Assay']].drop_duplicates().set_index('Experiment accession')\n",
    "assert not _assay_lookup.index.duplicated().any()\n",
    "_files_per_experiment = pd.DataFrame(_files_per_experiment).join(_assay_lookup).join(EXPECTED_NUMBER_OF_FILES, on='Assay')\n",
    "_files_per_experiment['wrong_number_of_files'] = _files_per_experiment['expected_number_of_files'] != _files_per_experiment['number_of_files']\n",
    "_files_per_experiment['wrong_number_of_files'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d8de9f-8ae8-48d0-93a7-828e21876e3c",
   "metadata": {},
   "source": [
    "If there are any multi-filename experiments left, just give up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b3c422-61f7-47bc-8f9f-7c7b819efc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = frozenset(_files_per_experiment[_files_per_experiment['wrong_number_of_files']].index)\n",
    "if to_remove:\n",
    "    print(\"Removing {:,} experiments because we couldn't figure out which peakset to use:\".format(len(to_remove)))\n",
    "    print(to_remove)\n",
    "    \n",
    "data_encode = data_encode[~data_encode['Experiment accession'].isin(to_remove)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f7c986-c559-4fae-b561-af97146b8024",
   "metadata": {},
   "source": [
    "At this point we have a more or less clean encode metadata set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb1f30e-e16e-4a26-baf5-7f8b21ad6c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca734dac-9943-43fa-9d76-84dbd92564a0",
   "metadata": {},
   "source": [
    "Now clean up the target information into column `Factor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d71ee14-f5a7-4eca-8dc9-1204731fa00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode['Experiment target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7c2507-d0d7-4732-805d-14ce82bdbc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode['Factor'] = data_encode['Experiment target'].str.rpartition('-')[0]\n",
    "data_encode['Factor'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495ec74a-faf7-466c-a5d5-ac24f0178c38",
   "metadata": {},
   "source": [
    "We cannot use the experiment target column for other assays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737f48a-d196-4c7b-bb4b-5e0c56660224",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode[data_encode['Factor'].isnull()]['Assay'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cf9bac-dc58-45bb-a384-4ce6743e4a2a",
   "metadata": {},
   "source": [
    "Instead use assay name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ee5290-ad58-474f-9363-74cff53cb31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode.loc[data_encode['Factor'].isnull(), 'Factor'] = data_encode.loc[data_encode['Factor'].isnull(), 'Assay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c0f0c5-0938-41ac-bac9-634036f1ac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode['Factor'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aa5c19-de22-4037-b167-731afecd47ed",
   "metadata": {},
   "source": [
    "Also assign factor types based on assay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57861c43-2d79-4a07-bce1-f4a17854d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode['FactorType'] = None\n",
    "data_encode.loc[data_encode['Assay'] == 'TF ChIP-seq', 'FactorType'] = 'protein'\n",
    "data_encode.loc[data_encode['Assay'] == 'Histone ChIP-seq', 'FactorType'] = 'feature_histone'\n",
    "\n",
    "data_encode.loc[data_encode['Assay'].isin(['DNase-seq', 'ATAC-seq']), 'FactorType'] = 'feature_accessibility'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefbae61-4100-4eb1-a7c7-bff95e2093a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode.loc[data_encode['FactorType'] == 'protein', 'Factor'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f941bfc2-07e8-4208-890b-86753a108ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode.loc[data_encode['FactorType'] == 'feature_histone', 'Factor'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a078bb39-e044-455a-a0ad-0b6ae0bbad6b",
   "metadata": {},
   "source": [
    "Join cell type columns into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f4db4-2cf2-4765-a027-1ce8d039d115",
   "metadata": {},
   "outputs": [],
   "source": [
    "CELL_TYPE_COLUMN = 'Cell_full_type'\n",
    "data_encode[CELL_TYPE_COLUMN] = data_encode[['Biosample type', 'Biosample term name']].apply(lambda x: '|'.join(map(str, x)), axis=1)\n",
    "data_encode[CELL_TYPE_COLUMN].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407ee637-3e8c-4dd1-8186-7c6df807113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode.groupby(['Assay', 'Output type']).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d96522-f64a-463e-a5e5-fcb79c0ce74a",
   "metadata": {},
   "source": [
    "Finally propose the filename download locations for each of the files (even if we won't end up using them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a267e9c8-4a59-4d59-99a2-545c534b696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_ext(path):\n",
    "    \n",
    "    base_path, ext = os.path.splitext(path)\n",
    "    if ext == '.gz':\n",
    "        base_path, intermediate_ext = os.path.splitext(base_path)\n",
    "        return intermediate_ext + ext\n",
    "    else:\n",
    "        return ext\n",
    "\n",
    "def get_filename(row):\n",
    "    \n",
    "    safe_cell_type_col = re.sub('[^a-zA-Z0-9]+', '_', row[CELL_TYPE_COLUMN])\n",
    "    safe_factor_col = re.sub('[^a-zA-Z0-9]+', '_', row['Factor'])\n",
    "    safe_id = re.sub('[^a-zA-Z0-9]+', '_', row.name)\n",
    "    ext = get_ext(row['File download URL'])\n",
    "    dataset = row['FactorType']\n",
    "    return os.path.join(param_encode_download_dir, f'encode_{dataset}', f'{safe_factor_col}.{safe_cell_type_col}.encode-{safe_id}{ext}')\n",
    "data_encode['Filename'] = data_encode.apply(get_filename, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c652c26-3f0f-4e3e-92cd-e2bc95d3eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b3b295-f347-4391-81fc-4a02150e5ea4",
   "metadata": {},
   "source": [
    "# Encode Proteins dataset: linking with MARCS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d65692f-a9d2-4855-b377-52e1ba033691",
   "metadata": {},
   "source": [
    "We will now create a map between ENCODE data and MARCS, we load the precomputed mapping between gene identifiers and MARCS labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee1dd1d-b3ba-4079-850c-dba30b6186fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_marcs = pd.read_csv(input_marcs_gene_label_map, sep='\\t')\n",
    "data_marcs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec872457-c351-4cb3-a0da-99c7ccfeef71",
   "metadata": {},
   "source": [
    "We will match datasets to MARCS based on lowercase gene names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d0299d-ab63-4434-9772-c2d6da417cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_marcs['gene_name_lowercase'] = data_marcs['gene_name'].str.lower()\n",
    "data_marcs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6393d61f-85e2-40f3-8d6e-d8104c2ebdd8",
   "metadata": {},
   "source": [
    "MARCS identifiers will be joined with a double bar: `||`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaac62e-d7e1-48a9-9f34-f4ed035d81ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "marcs_lookup = data_marcs.groupby('gene_name_lowercase').agg({'marcs_gene_label': param_gene_label_separator.join})['marcs_gene_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85384971-90ef-45d5-8833-cf2c3664a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "marcs_lookup[marcs_lookup.str.contains(\"\\|\\|\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c80ed-ed9c-46f5-ab36-8171c30d5782",
   "metadata": {},
   "source": [
    "Now we want to filter out proteins in ENCODE that match to MARCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e08ea9-98a0-477f-91e7-1ba86ae311ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode_proteins = data_encode.query(\"FactorType == 'protein'\")\n",
    "data_encode_proteins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc43280-7989-409d-8353-d859561ac2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode_proteins['Factor_lowercase'] = data_encode_proteins['Factor'].str.lower()\n",
    "\n",
    "encode_proteins_all = set(data_encode_proteins['Factor_lowercase'].unique())\n",
    "encode_proteins_in_marcs = encode_proteins_all & set(marcs_lookup.index)\n",
    "\n",
    "print(\"{:,}/{:,} ({:.2%}) of unique ENCODE protein names can be matched to MARCS data\".format(\n",
    "    len(encode_proteins_in_marcs), len(encode_proteins_all), len(encode_proteins_in_marcs)/len(encode_proteins_all)\n",
    "))\n",
    "\n",
    "marcs_gene_labels_with_encode_ids = marcs_lookup.loc[encode_proteins_in_marcs].str.split('\\|\\|', expand=True).stack().unique()\n",
    "print(\"This corresponds to {:,} unique gene labels in MARCS \".format(len(marcs_gene_labels_with_encode_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557287e4-0414-435e-ad82-ef0c2c065900",
   "metadata": {},
   "source": [
    "Leave only data with MARCS labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be69f2-3f21-4e0a-861f-fdb3a7e05f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode_proteins = pd.merge(data_encode_proteins, marcs_lookup, left_on='Factor_lowercase', right_index=True, how='inner')\n",
    "data_encode_proteins = data_encode_proteins.drop(columns='Factor_lowercase')\n",
    "data_encode_proteins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a947a445-5121-4e46-809c-b3f3f3c20499",
   "metadata": {},
   "source": [
    "Break down the results by cell line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad8958c-011d-46b6-aeb0-2c941ef5bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_line_counts = data_encode_proteins.groupby(CELL_TYPE_COLUMN)['Factor'].nunique()\n",
    "cell_line_counts.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43dd3cf-e147-4166-966f-361e63e0c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_lines_to_keep = {f'cell line|{param_cell_line}'}\n",
    "print('Keeping only the data from:', ', '.join(cell_lines_to_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e214fc-bc74-4353-a95f-1cd0d3d32232",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode_proteins = data_encode_proteins[data_encode_proteins[CELL_TYPE_COLUMN].isin(cell_lines_to_keep)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f499e3c-7847-497e-a363-411ce5930efd",
   "metadata": {},
   "source": [
    "This leaves this many unique factors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c51e376-2891-47f0-91b9-8443a38adb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode_proteins['Factor'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53b358f-7748-4c89-b28b-e50349b91d80",
   "metadata": {},
   "source": [
    "Representing this many MARCS IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f173571-cd10-4d72-afec-80316fd78af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode_proteins['marcs_gene_label'].str.split('\\|\\|', expand=True).stack().nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c71ff3-9364-4dfa-8b3b-8ba9b17362b4",
   "metadata": {},
   "source": [
    "Let's make a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a633447e-d01f-4200-9789-6c167b166cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = data_encode_proteins.groupby(['marcs_gene_label', CELL_TYPE_COLUMN]).size()\n",
    "matrix = matrix.unstack(CELL_TYPE_COLUMN)\n",
    "\n",
    "_cmap = sns.clustermap(\n",
    "   matrix.fillna(0), mask=matrix.isnull(), \n",
    "    row_cluster=len(matrix.columns) > 1,\n",
    "    col_cluster=len(matrix.columns) > 1,\n",
    "    metric='cosine', method='complete', \n",
    "    annot=matrix,\n",
    "    fmt='.0f',\n",
    "   linewidth=1,\n",
    "   cmap='GnBu',\n",
    "   figsize=(FIVE_MM_IN_INCH*1.8*(len(matrix.columns)), FIVE_MM_IN_INCH*(len(matrix)) * 0.6),\n",
    "   yticklabels=1,\n",
    ")\n",
    "_cmap.cax.set_ylabel(\"Number of datasets\")\n",
    "_cmap.ax_heatmap.xaxis.set_tick_params(length=0)\n",
    "_cmap.ax_heatmap.yaxis.set_tick_params(length=0)\n",
    "\n",
    "# _cmap.savefig(os.path.join(output_plots_dir, 'n_encode_datasets_per_cell_line_per_marcs_label.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d11905-e5da-4f1d-bae5-06546b991287",
   "metadata": {},
   "source": [
    "# Encode feature data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d733ceb-07dc-4d8a-8988-c92413a5c041",
   "metadata": {},
   "source": [
    "Unlike protein datasets, we only need to filter the faetures by cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233faf6d-26de-4e55-9f27-457188cb3ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = {}\n",
    "for feature in ['feature_histone', 'feature_accessibility']:\n",
    "    data_feature = data_encode.query(\"FactorType == @feature\")\n",
    "    data_feature = data_feature[data_feature[CELL_TYPE_COLUMN].isin(cell_lines_to_keep)]\n",
    "\n",
    "    data_features[feature] = data_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c46ec5-5b52-4ac7-9609-541f11abdb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features['feature_histone'].groupby('Factor').size().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac285ef3-b9c3-4bc1-acb2-fedf5a27ea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features['feature_accessibility'].groupby('Factor').size().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320b70fb-c027-4d3d-92d8-ac531a942e83",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b935b823-7254-4a67-a471-e5864bb7a647",
   "metadata": {},
   "source": [
    "At this point we're done so what's only left is to save the output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d7da1-61c6-457f-ba0d-aece22ea0f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encode_proteins.sort_index().to_csv(output_tsvs['protein'], sep='\\t')\n",
    "for feature, df in data_features.items():\n",
    "    df.sort_index().to_csv(output_tsvs[feature], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44440c94-f742-4ec4-8b4c-46b73f41fd70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
